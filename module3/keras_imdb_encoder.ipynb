{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b40afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieljoo/Code/ai_bootcamp/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/danieljoo/Code/ai_bootcamp/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras.utils import pad_sequences\n",
    "import keras_hub\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde36241",
   "metadata": {},
   "source": [
    "# TIME FOR THE TRANSFORMER!!!\n",
    "\n",
    "Woohoo, I'm finally up to this point and I'm super excited. First some readings:\n",
    "\n",
    "1. [3Blue1Brown](https://www.youtube.com/watch?v=wjZofJX0v4M&ab_channel=3Blue1Brown)\n",
    "2. [Stat Quest](https://www.youtube.com/watch?v=zxQyTK8quyY&ab_channel=StatQuestwithJoshStarmer)\n",
    "3. [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "4. [Attention is All you Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89541383",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 100\n",
    "VOCAB_SIZE = 1000\n",
    "MAX_SEQUENCE_LEN = 128\n",
    "FFN_DIM = 4 * EMBED_DIM\n",
    "NUM_HEADS = 2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n",
    "    num_words=VOCAB_SIZE,\n",
    "    maxlen=MAX_SEQUENCE_LEN,\n",
    ")\n",
    "\n",
    "x_train = pad_sequences(x_train, MAX_SEQUENCE_LEN)\n",
    "x_test = pad_sequences(x_test, MAX_SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self,num_heads, key_dim, value_dim=None):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.value_dim = value_dim if value_dim is not None else key_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        embed_dim = input_shape[-1]\n",
    "        self.permute1 = keras.layers.Permute((2,1,3))\n",
    "        self.permute2 = keras.layers.Permute((1,3,2))\n",
    "        self.wq = self.add_weight(\n",
    "            shape=(embed_dim,self.key_dim*self.num_heads),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.wk = self.add_weight(\n",
    "            shape=(embed_dim,self.key_dim*self.num_heads),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.wv = self.add_weight(\n",
    "            shape=(embed_dim, self.value_dim * self.num_heads),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.wo = self.add_weight(\n",
    "            shape=(self.value_dim * self.num_heads, embed_dim),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='wo'\n",
    "        ) \n",
    "        \n",
    "    \n",
    "    def call(self,query,key,value, mask=None):\n",
    "        batch_size = ops.shape(query)[0]\n",
    "        seq_len_q = ops.shape(query)[1]\n",
    "        seq_len_kv = ops.shape(key)[1]\n",
    "        \n",
    "        queries = ops.matmul(query, self.wq) # BxNxE x ExKn = BxNxKn\n",
    "        keys = ops.matmul(key, self.wk) #BxNxE x ExKn = BxNxKn\n",
    "        values = ops.matmul(value, self.wv) #BxNxE x ExVn = BxNxVn\n",
    "        \n",
    "        queries = ops.reshape(queries, (batch_size, seq_len_q, self.num_heads, self.key_dim)) #BxNxnxK\n",
    "        keys = ops.reshape(keys, (batch_size, seq_len_kv, self.num_heads, self.key_dim))\n",
    "        values = ops.reshape(values, (batch_size, seq_len_kv, self.num_heads, self.key_dim))# BxNxnxV\n",
    "        \n",
    "        queries = self.permute1(queries) #BxnxNxK\n",
    "        keys = self.permute1(keys) #BxnxNxK\n",
    "        values = self.permute1(values) #BxnxNxV\n",
    "        \n",
    "        keys = self.permute2(keys) # BxnxKxN\n",
    "        \n",
    "        scores = ops.matmul(queries, keys) # BxnxNxN\n",
    "        \n",
    "        scaling_factor = ops.sqrt(ops.cast(self.key_dim, dtype=queries.dtype))\n",
    "        normalized_scores = scores / scaling_factor\n",
    "        if mask is not None:\n",
    "            # Original mask shape: (Nq, Nkv)\n",
    "            # This allows it to broadcast correctly to (B, H, Nq, Nkv)\n",
    "            mask = mask[None, None, :, :]\n",
    "            normalized_scores += (1.0 - ops.cast(mask, dtype=normalized_scores.dtype)) * -1e9\n",
    "        attentions = keras.activations.softmax(normalized_scores) # BxnxNxN\n",
    "        attentions = ops.matmul(attentions, values) #BxnxNxN x BxnxNxV = BxnxNxV\n",
    "        \n",
    "        attentions = self.permute1(attentions) #BxNxnxV\n",
    "        concatenated_output = ops.reshape(attentions, (batch_size, seq_len_q, self.value_dim*self.num_heads)) #BxNxVn\n",
    "        \n",
    "        attentions = ops.matmul(concatenated_output, self.wo) #BxNxVn x BxVnxE = BxNxE\n",
    "        return attentions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279161f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myEncoderBlock(keras.layers.Layer):\n",
    "    def __init__(self,embed_dim,num_heads,ffn_dim, rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ffn_dim = ffn_dim\n",
    "        self.rate = rate\n",
    "        self.mha_layer = myMultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=self.embed_dim // self.num_heads\n",
    "        )\n",
    "        \n",
    "        self.dense1 = keras.layers.Dense(4*embed_dim, activation='relu')\n",
    "        self.dense2 = keras.layers.Dense(self.embed_dim)\n",
    "        \n",
    "        self.layernorm_1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm_2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.add_1 = keras.layers.Add()\n",
    "        self.add_2 = keras.layers.Add()\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        seq_len = ops.shape(inputs)[1]\n",
    "        \n",
    "        causal_mask = ops.logical_not(ops.triu(ops.ones((seq_len, seq_len)), k=1))\n",
    "        \n",
    "        mha_output = self.mha_layer(\n",
    "            query=inputs,\n",
    "            key=inputs,\n",
    "            value=inputs,\n",
    "            mask=causal_mask\n",
    "        )\n",
    "        \n",
    "        add_norm_1 = self.add_1([inputs, mha_output])\n",
    "        add_norm_1 = self.layernorm_1(add_norm_1)\n",
    "        \n",
    "        ffn_output = self.dense1(add_norm_1)\n",
    "        ffn_output = self.dense2(ffn_output)\n",
    "\n",
    "        add_norm_2 = self.add_2([add_norm_1, ffn_output])\n",
    "        normalized_outputs = self.layernorm_2(add_norm_2)\n",
    "        \n",
    "        return normalized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "470ddc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"imdb_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"imdb_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_encoder_block_5  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">120,900</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">myEncoderBlock</span>)    │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_encoder_block_6  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">120,900</span> │ my_encoder_block… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">myEncoderBlock</span>)    │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ my_encoder_block… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m100,000\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │     \u001b[38;5;34m12,800\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mPositionEmbedding\u001b[0m) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_encoder_block_5  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m120,900\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mmyEncoderBlock\u001b[0m)    │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ my_encoder_block_6  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m120,900\u001b[0m │ my_encoder_block… │\n",
       "│ (\u001b[38;5;33mmyEncoderBlock\u001b[0m)    │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ my_encoder_block… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m101\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">354,701</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m354,701\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">354,701</span> (1.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m354,701\u001b[0m (1.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(MAX_SEQUENCE_LEN,),dtype='int32')\n",
    "\n",
    "#embedding\n",
    "token_embeddings = keras.layers.Embedding(\n",
    "    input_dim = VOCAB_SIZE, \n",
    "    output_dim =EMBED_DIM\n",
    ")(inputs)\n",
    "position_embeddings = keras_hub.layers.PositionEmbedding(\n",
    "    sequence_length=MAX_SEQUENCE_LEN,\n",
    ")(token_embeddings)\n",
    "embeddings = token_embeddings + position_embeddings\n",
    "\n",
    "#encoder block\n",
    "x = myEncoderBlock(EMBED_DIM, NUM_HEADS, FFN_DIM)(embeddings)\n",
    "x = myEncoderBlock(EMBED_DIM, NUM_HEADS, FFN_DIM)(x)\n",
    "\n",
    "pooled_output = keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = keras.layers.Dense(1,)(pooled_output)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='imdb_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f0590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 210ms/step - accuracy: 0.4903 - loss: 0.9317 - val_accuracy: 0.4679 - val_loss: 0.6832\n",
      "Epoch 2/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 206ms/step - accuracy: 0.5214 - loss: 0.7064 - val_accuracy: 0.4739 - val_loss: 0.6351\n",
      "Epoch 3/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 239ms/step - accuracy: 0.6153 - loss: 0.6191 - val_accuracy: 0.7755 - val_loss: 0.4928\n",
      "Epoch 4/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 212ms/step - accuracy: 0.7328 - loss: 0.5090 - val_accuracy: 0.7584 - val_loss: 0.4533\n",
      "Epoch 5/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 204ms/step - accuracy: 0.7751 - loss: 0.4558 - val_accuracy: 0.7558 - val_loss: 0.4449\n",
      "Epoch 6/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 204ms/step - accuracy: 0.8097 - loss: 0.4002 - val_accuracy: 0.7952 - val_loss: 0.4448\n",
      "Epoch 7/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 208ms/step - accuracy: 0.8304 - loss: 0.3760 - val_accuracy: 0.8029 - val_loss: 0.5236\n",
      "Epoch 8/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 201ms/step - accuracy: 0.8054 - loss: 0.4328 - val_accuracy: 0.7926 - val_loss: 0.4198\n",
      "Epoch 9/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 201ms/step - accuracy: 0.8473 - loss: 0.3411 - val_accuracy: 0.8081 - val_loss: 0.4354\n",
      "Epoch 10/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 204ms/step - accuracy: 0.8636 - loss: 0.3600 - val_accuracy: 0.7361 - val_loss: 0.4824\n",
      "Epoch 11/15\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 200ms/step - accuracy: 0.8593 - loss: 0.3127 - val_accuracy: 0.7721 - val_loss: 0.4438\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.7927 - loss: 0.4172\n",
      "Test Loss: 0.418856680393219\n",
      "Test Accuracy: 0.7899807095527649\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',     \n",
    "    patience=3,      \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss= keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.RMSprop(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=15, \n",
    "    batch_size=64, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping_callback])\n",
    "\n",
    "test_scores=model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(f'Test Loss: {test_scores[0]}')\n",
    "print(f'Test Accuracy: {test_scores[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d570d7",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "So first the single head attention block was less complicated than I expected since it's all just matrix multiplications. The biggest hiccup was probably when I chose to expand to multi-head because I found online that I was better off doing some matrix manipulations to multiplying big flat matrixes rather than just parallelize it with a 'head' dimension (I was tempted though). I didn't really consider cross attention in this model, but I think that's just debugging and throwing some variables around\n",
    "\n",
    "Additionally, I learned while building this that the transformer architecture is not agreed upon, and the most that the native keras api can give us without becoming opinionated is the multi-head attention layer, which truthfully sticks to the \"Attention is All you Need\" paper and remains a proven, robust fundamental building block.\n",
    "\n",
    "I built both the mha_layer and the encoder. The MHA is mathematically pretty standard but the encoder can be built in many different ways like:\n",
    "- Pre vs post normalization (I used post as the paper did)\n",
    "- Feed Forward network activation choices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
